{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as plt #Plotting lib\nimport seaborn as sbs # Visualization\nimport scipy # Stats\nfrom sklearn.preprocessing import LabelEncoder # For encoding categorical variables\nfrom sklearn.model_selection import train_test_split # spliting into train test\nfrom sklearn.linear_model import LinearRegression # Linear Regression\nfrom sklearn.metrics import mean_squared_error # MSE\nfrom sklearn.linear_model import Ridge # Ridge regressiojn\nfrom sklearn.linear_model import Lasso # Lasso regression\nfrom sklearn.cross_validation import cross_val_score # Cross validation \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ff4722423084f67656c35f3e219eb27f45598946",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Extracting Basic info about Train and Test data frame\nprint ('Shape of train: ' + str(train_df.shape))\nprint ('Shape of test: ' + str(test_df.shape))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24b616cd1b7a7ab1be13a7f1a950c91d10d99b71",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9de1c00ddf50147bc9d084c3a2ff1fb07a56c261",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_df.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ab13fcaeab3c5f4652b2d280f653e289636eeb49",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efbe414ae3ae2197924ab714c6433521772ead26",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "04ab56045aecc181fc32ae1e3e1dab0ed877defe"
      },
      "cell_type": "code",
      "source": "#Delete ID Feature as it is completely useless.\ndel train_df['Id']\ndel test_df['Id']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "102eae0f2911866854d5efac382df65219f4e77e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Statistics of Numerical Data\ntrain_df.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ea164cc37145ff36dbc4d5e7047f45faa66f7684"
      },
      "cell_type": "markdown",
      "source": "**Data Exploration **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ab49c0fff5f814b17487d6499aaa827495a1273",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Distribution of Response variable - 'Sales Price'\nsbs.distplot(train_df['SalePrice'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6c4099c93966182c4f3b728d77ed34af9415794",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#As the distribution is slightly right skewed, we make it almost normal using log transformation\n# But we will do it afterwards.\n\ntrain_df['LogSalePrice'] = np.log(train_df['SalePrice'])\nsbs.distplot(train_df.LogSalePrice)\n#Much perfect normalized thing.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9450ada7e04f9ee8f46c9837f038daf17239c884",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Look for corelation between dependent variables and independent variable\ncorr = train_df.corr()\ncorr = corr['SalePrice']\ncorr[np.argsort(corr, axis=0)[::-1]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dc593919c77c0ab568ced4afa23a2a8db1c8e294"
      },
      "cell_type": "markdown",
      "source": "Following are the variables with corr > 0.5, this gives some intuition of their involvement in sales price.\n* SalePrice        \n* OverallQual      \n* GrLivArea        \n* GarageCars       \n* GarageArea       \n* TotalBsmtSF      \n* FullBath         \n* 1stFlrSF         \n* YearBuilt        \n* YearRemodAdd     \n* GarageYrBlt      \n* TotRmsAbvGrd    \n\nFollowing two have slightly negative coefficient of correlation, shows iverse relation with sales price.\n\n* KitchenAbvGr    \n* EnclosedPorch  "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f76c0c8e516bf35017ad47e459494ebdc00897f3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "corrMatrix=train_df[[\"SalePrice\",\"OverallQual\",\"GrLivArea\",\"GarageCars\",\n                  \"GarageArea\",\"GarageYrBlt\",\"TotalBsmtSF\",\"1stFlrSF\",\"FullBath\",\n                  \"TotRmsAbvGrd\",\"YearBuilt\",\"YearRemodAdd\"]].corr()\n\nplt.pyplot.figure(figsize=(10, 10))\n\nsbs.heatmap(corrMatrix,vmax=.8, linewidths=0.01,\n            square=True,annot=True,cmap='plasma',linecolor=\"white\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f3352828133d5bd3f65488d8e63cc96fd6d0e236"
      },
      "cell_type": "markdown",
      "source": "To reduce the multicollinearity, i.e. high correlation betweeen dependent variable we choose certain features from heatmap such that there is no multicollinearity while training our model.\n\nWe look at all the yellow boxes, i.e. with corr coef > 0.8. So, we find such pairs to be: \n* (TotRmsAbvGrd, GrLivArea)\n* (YearBuilt, GarageYrBuilt)\n* (1stFlrSF, TotalBsmntSF)\n* (GarageAreas, GarageCars)\n\nTo reduce the effect of multicollinearity we will simply Remove one feature from each of the pair. (Afterwards, ofcourse.)"
    },
    {
      "metadata": {
        "_uuid": "8c63a877d2b13d6f48db57c939f6e6b1ff5edf25"
      },
      "cell_type": "markdown",
      "source": "### Missing Value Imputation"
    },
    {
      "metadata": {
        "_uuid": "e39ddb4938d52687d753e868e6408f8ad5f4f9d5"
      },
      "cell_type": "markdown",
      "source": "In this we can see Only one variable(GarageyrrBlt) has null values which is to be used in training our data set, we impute these values. These are years which have to be integers for sure. Is it good to assume that Garage is  built on the same day as home? "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eed60e8a18d3572e71ebc6dcfd889da42a2cf112",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df[train_df['GarageYrBlt'] == train_df['YearBuilt']].OverallQual.count()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bfa83d6c7fa99c124bb004ecb3f801b618eec181"
      },
      "cell_type": "markdown",
      "source": "1089 is quite large number of total, so we should assume that most of the garages are built with building only, so we reaplace empty values with YearBuilt."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "794c4142cd49e489ba9ac3adb4baa2c22af4c751"
      },
      "cell_type": "code",
      "source": "train_df.GarageYrBlt.fillna(train_df['YearBuilt'], inplace= True)\ntest_df.GarageYrBlt.fillna(train_df['YearBuilt'], inplace= True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "520b9995fec7fbd6833def06374709109c2473e0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "null_columns=train_df.columns[train_df.isnull().any()]\ntrain_df[null_columns].isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "96ef1fe1c3c7aac42b3042a5f8909991bc0af281"
      },
      "cell_type": "markdown",
      "source": "##### Lot Frontage"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "32889366966d1b9e8082d874066b591fa772ae4e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#259 Missing value, there is another feature which is related to Lot, i.e. LotArea.\n# First see correlation between them\ntrain_df[['LotArea', 'LotFrontage']].corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "7f0334cd3833d7681eda88f5a6d5bfdc43c7b8a3"
      },
      "cell_type": "code",
      "source": "#Correlation is very less, let's try with sqrt of LotArea\ntrain_df['sqrtLotArea'] = np.sqrt(train_df['LotArea'])\ntest_df['sqrtLotArea'] = np.sqrt(test_df['LotArea'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3d37478a97f093728f3fb49ef40506e152687566",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_df[['sqrtLotArea', 'LotFrontage']].corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ca73c3c0a7253bd4c430ab79396c870f2579954e"
      },
      "cell_type": "code",
      "source": "#correlation is good, replace NAN by sqrtLotArea\ntrain_df.LotFrontage.fillna(train_df['sqrtLotArea'], inplace = True)\ntest_df.LotFrontage.fillna(test_df['sqrtLotArea'], inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e624e1b78afc42854ee7106db05fe0300a835863"
      },
      "cell_type": "markdown",
      "source": "### ALLEY"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a99ce22eb5cbe9a549ce85b7d3f704429a683af3"
      },
      "cell_type": "code",
      "source": "#Most of the values are Null replace by 'None'\ntrain_df.Alley.fillna('None', inplace= True)\ntest_df.Alley.fillna('None', inplace= True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5923461deb61a548f83afe78ef59f4b8defea58b"
      },
      "cell_type": "markdown",
      "source": "#### MAS VNR TYPE AND AREA"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4c5e9bebf2045ff7300eb327d5e68cc329295d90"
      },
      "cell_type": "code",
      "source": "cols = ['MasVnrType','MasVnrArea']\nfor items in cols:\n    if train_df[items].dtype == 'object':\n        train_df[items].fillna('None', inplace = True)\n    elif train_df[items].dtype == 'float64':\n        train_df[items].fillna(0.0, inplace = True)\nfor items in cols:\n    if test_df[items].dtype == 'object':\n        test_df[items].fillna('None', inplace = True)\n    elif test_df[items].dtype == 'float64':\n        test_df[items].fillna(0.0, inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cf57db2bdf9fe6f07bfaeb8838036baff0739677"
      },
      "cell_type": "markdown",
      "source": "#### Basement"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0c48080eeeb31ceb6c815d66ce115221be374369"
      },
      "cell_type": "code",
      "source": "#Almost anything with no basement have NAN value, replace it ny None\n\ncols =[ u'BsmtQual',\n       u'BsmtCond', u'BsmtExposure', u'BsmtFinType1',\n       u'BsmtFinType2']\n\nfor col in cols:\n    train_df[col].fillna('None', inplace = True)\nfor col in cols:\n    test_df[col].fillna('None', inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "02c30b9203e2bf53cf9018050d6a75bf0a2e8bd1"
      },
      "cell_type": "markdown",
      "source": "#### Garage"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f88fbb3cd85eec0d3464139b9ba55fb82796ca53"
      },
      "cell_type": "code",
      "source": "#Since all the cols with NAN is correcponding to houses with ni garage, we replace NAN by None\ncols = ['GarageType',\n'GarageFinish',\n'GarageQual',\n'GarageCond' ]\n\nfor col in cols:\n    train_df[col].fillna('None', inplace = True)\nfor col in cols:\n    test_df[col].fillna('None', inplace = True)\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1eebbfb305fdf61151d679f3cf6a51b4b90d3d6f"
      },
      "cell_type": "markdown",
      "source": "#### Electrical"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0c5e12696d52fa89f836b514a9602fa14f27f3f4"
      },
      "cell_type": "code",
      "source": "# Only one value needs to fill up, so replace by mode\ntrain_df.Electrical.fillna('SBrkr', inplace = True)\ntest_df.Electrical.fillna('SBrkr', inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "afb18f2c9e6bf454062b4187d9ae7c331794f2ce"
      },
      "cell_type": "markdown",
      "source": "#### FirePlaceQu"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a69f3632db7e1bba0e65c979365c05ecb81fa287"
      },
      "cell_type": "code",
      "source": "train_df.FireplaceQu.fillna('None', inplace = True)\ntest_df.FireplaceQu.fillna('None', inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7bc3624879b7635e2d54a87d6df16817bb29d9a8"
      },
      "cell_type": "markdown",
      "source": "#### Pools, Fence & Misc"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9d35efdcbed63e80b21d9590a673475c4fea865a"
      },
      "cell_type": "code",
      "source": "#Pools definitely may have effect on prices. Although not much houses have pools, but for safety let us replace NAN by None\ntrain_df.PoolQC.fillna('None', inplace= True)\ntrain_df.Fence.fillna('None', inplace= True)\ntrain_df.MiscFeature.fillna('None', inplace= True)\ntest_df.PoolQC.fillna('None', inplace= True)\ntest_df.Fence.fillna('None', inplace= True)\ntest_df.MiscFeature.fillna('None', inplace= True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2da61b19b04e0e6a14df5d30e3955dd247feccc6"
      },
      "cell_type": "markdown",
      "source": "# Outlier Detection and Handling "
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "665a2bd610580cb956c48dad86d4a2b11261538e"
      },
      "cell_type": "code",
      "source": "# We use tukey method i.e. anything outside IQR * 1.5 is considered outlier, but it is removing som many points \n# So we are going to use IQR * 3\ndef Outlier(col, train_df):\n    Q3 = train_df[col].describe().iloc[6]  \n    Q1 = train_df[col].describe().iloc[4]\n    IQR = Q3 - Q1\n    Tukey_coeff = 3*IQR\n    Lower_bound = Q1 - Tukey_coeff\n    Upper_bound = Q3 + Tukey_coeff\n    train_df = train_df[(train_df[col] > Lower_bound) & (train_df[col] < Upper_bound)]\n    return train_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "db6f8044bc69b12b0bf8aff26dcffab9f973cdd6"
      },
      "cell_type": "code",
      "source": "#We reamove Outliers from main numeric data which influence our model\ncol = [\"SalePrice\",\"OverallQual\",\"GrLivArea\",\"GarageCars\",\n                  \"GarageArea\",\"GarageYrBlt\",\"TotalBsmtSF\",\"1stFlrSF\",\"FullBath\",\n                  \"TotRmsAbvGrd\"]\nfor cols in col:\n    train_df = Outlier(cols, train_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d43f848fb47a2b43795d011d6aa14f7cb7cebff1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print (train_df.shape)\nprint (test_df.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "05618f9815f2552948e96d11b6865c4b5815ab4d"
      },
      "cell_type": "markdown",
      "source": "## Effect of different features on Sale Price\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0e9b5963ef8595caefa5a4a8254dff0fad1a47f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sbs.pairplot(train_df[col[0:4]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7cb94a8079c6e9474f760d4c0b4f1167e8bc7289"
      },
      "cell_type": "markdown",
      "source": "* POlynomial or quadratic relationship can be seen b/w Overall Quality and sales price.\n* Linear relationship between GrLivArea and Sales Price\n* Median of sales price also increases with in GragesCars\n* Most garages have capacity of 2"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ba6c94ac9f42d7dbc2028cb4cc5dcbe2f383de7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sbs.pairplot(train_df[['SalePrice', \"GarageArea\",\"GarageYrBlt\",\"TotalBsmtSF\"]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1150ec7c5dc5c88a4ca1ab5d116e4f7082972231"
      },
      "cell_type": "markdown",
      "source": "* Salesprice increases with Garage area and BsmntSF, almost linearly.\n* Prices increase quadrartically as newly constructed the house is.\n* Building garages became more popular as passage of time."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8b3b4eb20dde3eeb40174a7d3f44cb414426b72",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.pyplot.figure(figsize = (20,20))\ntrain_df.boxplot(column='SalePrice', by = 'Neighborhood', figsize = (12,12), fontsize = 0.5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd3ab9452bfc34ae242526cee9d84ee89a7a7dc5"
      },
      "cell_type": "markdown",
      "source": "## few nbd have really high prices of property, so must use nbd in our modeling."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4efddac0ee42a56c1485cc97926ccf35ddf333f8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "catg_var = train_df.dtypes[train_df.dtypes == \"object\"].index\nfor catg in list(catg_var) :\n    bp = train_df.boxplot(column=['LogSalePrice'], by=[catg])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "346252b423d2048d9415f521933c105a821b2bc6"
      },
      "cell_type": "markdown",
      "source": "Upon seeing the relationship between categorical and sale prices, we can see that few cat. variables have very much impact \non sale price so we will use only those features in our analysis.: \n    \n'Neighborhood', 'Condition2', 'MasVnrType', 'ExterQual', 'BsmtQual','CentralAir', 'Electrical', 'KitchenQual', 'SaleType'"
    },
    {
      "metadata": {
        "_uuid": "adb61a8ee699b387ea47dc6da33056d2e2d3dc00"
      },
      "cell_type": "markdown",
      "source": "### Encoding Categorical variables to numerical"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68472f8867bf77697c9231ee06f9e898c1ed56e5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "cat = ['Neighborhood', 'Condition2', 'MasVnrType', 'ExterQual', 'BsmtQual','CentralAir', 'Electrical', 'KitchenQual', 'SaleType']\nlb_make = LabelEncoder()\nfor col in cat:\n    train_df[\"num\" + col] = lb_make.fit_transform(train_df[col].astype(str))\nfor col in cat:\n    test_df[\"num\" + col] = lb_make.fit_transform(test_df[col].astype(str))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46086eaf8104e3ec935c296f4a051c8aae0364f1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print (train_df.shape)\nprint (test_df.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8fcced088bd23a61616eb385eb64bfecde8d6e66"
      },
      "cell_type": "code",
      "source": "#correlation between categorical and target variable\ncat = ['Neighborhood', 'Condition2', 'MasVnrType', 'ExterQual', 'BsmtQual','CentralAir', 'Electrical', 'KitchenQual', 'SaleType']\nnumcat = ['num'+item for item in cat]\nnumcat.append('LogSalePrice')\ncorr = train_df[numcat].corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca87278624b18218a496263fdb9c52366eeace42",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.pyplot.figure(figsize=(10, 10))\nsbs.heatmap(corr,vmax=.8, linewidths=0.01,\n            square=True,annot=True,cmap='plasma',linecolor=\"white\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c3d9621ac777dd3e85331ea018a85c633e808625"
      },
      "cell_type": "markdown",
      "source": "* numExterQual, numBsmtQual, numKitchenQual are highly related to sales price, but all of the are correlated to each other also so we only use one of them to reduce multicollinearity.\n* numCentralAir is also related and will be used for model training."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f0b6bc89e458bd9bdf7a31d39e0805473f9feb46"
      },
      "cell_type": "code",
      "source": "#Total Columns which we are considering for model evaluation:\nhero_col = [\"OverallQual\",\"GrLivArea\",\n                  \"GarageArea\",\"TotalBsmtSF\",\"FullBath\",\n                  \"YearBuilt\",\"YearRemodAdd\",\"numKitchenQual\", 'numCentralAir','numNeighborhood', 'LogSalePrice']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "37d7f5be649ba327b88bbaf999702f3c4432fb1c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X = train_df[hero_col[:-1]]\ny = train_df[hero_col[-1]]\nX_maintest = test_df[hero_col[:-1]]\nX_maintest.dropna(inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "23e40a5e67d7efd08e1b2a3eff1cbbc3cc70fb68"
      },
      "cell_type": "code",
      "source": "# Test train split of train_df\nX_train, X_test, y_train, y_test = train_test_split(\n                                    X, y, random_state=42, test_size=.33)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0aab41c9a0a12520ea66571355bc002618c5ba05"
      },
      "cell_type": "markdown",
      "source": "## OLR, ordinary linear regression."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ebfb5d5badb438a4b2eba3d82fe8e7d9fe6a6808",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model = LinearRegression()\nlr = model.fit(X_train, y_train)\nb = lr.score(X_test, y_test)  \nprint ('R^2 error is %s.'% b)\nmean_s_e = mean_squared_error(lr.predict(X_test), y_test)\nprint ('MSE is %s.' % mean_s_e)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cacc411e934dd050c88cf2be2b0140aacf2e5d15",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "residuals = lr.predict(X_test) - y_test\nfig = sbs.jointplot( lr.predict(X_test), residuals,kind='reg')\nfig.set_axis_labels('Fitted','Residuals')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "20ddc9aaadad78d24d2dfdbb6b60924fbc6a54e6"
      },
      "cell_type": "markdown",
      "source": "* Error is almost normally distributed.\n* No pattern observed, whatsover. No transformation needed.\n* Plot is not funnel shapped, Heteroskedasticity is not there."
    },
    {
      "metadata": {
        "_uuid": "08657c4043d0fc4ea21194ff584e0d3742c015f7"
      },
      "cell_type": "markdown",
      "source": "### Using Cross validation to see possible overfitting"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bfdb5664ad0ad645800ab670183b07484e73e1d3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#New Model training which will include all the observation for training.\nNew_lr = LinearRegression()\nNew_model = New_lr.fit(X,y)\nscores = cross_val_score(New_lr, X, y , cv =10, scoring= 'r2')\n#SE_scores = - cross_val_score(New_lr, X, y, cv =10, scoring= 'mean_squared_error')\nprint ('Mean of all the R^2 error after 10 folds of CV is %s.'% scores.mean())\n#rint 'Mean of MSE after 10 folds of CV is %s.' % MSE_scores.mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "59b27c6056079f40236ac807515dc3ea18a98238"
      },
      "cell_type": "markdown",
      "source": "##### Ridge Regression, finding optimal parameter of ridge regression using MSE\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d30dd19d6fc0412f47db75218e865e8844f077e5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "R2 = []\nalphas = []\nmse = []\nfor i in range (-2,3):\n    alpha = 10**i      # Range of alphas \n    rm = Ridge(alpha=alpha)   \n    ridge_model = rm.fit(X_train, y_train)\n    preds_ridge = ridge_model.predict(X_test)    #Training and predicting Ridge model\n    plt.pyplot.scatter(preds_ridge, y_test, alpha=.75, color='b')\n    plt.pyplot.xlabel('Predicted Price')\n    plt.pyplot.ylabel('Actual Price')\n    plt.pyplot.title('Ridge Regularization with alpha = {}'.format(alpha))    #Plotting actual vs predicted price for difft alphas\n    R2.append(rm.score(X_test, y_test))\n    mse.append(mean_squared_error(y_test, preds_ridge))\n    #rmse = np.sqrt(mse)\n    alphas.append(alpha)\n    print ('R2 Error for alpha = %s is %s'%(alpha, rm.score(X_test, y_test)))\n    plt.pyplot.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3647578d576c50856b390cb02bb4baad6d384b14",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.pyplot.plot(alphas, mse)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "581ff668335789a55df7eabab539e4eb508b1df9"
      },
      "cell_type": "markdown",
      "source": "##### Minimized MSE is at 10.. So, value of alpha can be choosen to be 10."
    },
    {
      "metadata": {
        "_uuid": "8ecbbde533ba7ad98c7c5a724a3ed524e54183e4"
      },
      "cell_type": "markdown",
      "source": "Lasso Regression "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c758e70cfa6c2921976f7ec2f6cea17ca67bc5e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "R2 = []\nalphas = []\nmse = []\nfor i in range (-5,3):\n    alpha = 10**i\n    ls = Lasso(alpha=alpha)\n    lasso_model = ls.fit(X_train, y_train)\n    preds_lasso = lasso_model.predict(X_test)\n    plt.pyplot.scatter(preds_lasso, y_test, alpha=.75, color='b')\n    plt.pyplot.xlabel('Predicted Price')\n    plt.pyplot.ylabel('Actual Price')\n    plt.pyplot.title('Lasso Regularization with alpha = {}'.format(alpha))\n    R2.append(ls.score(X_test, y_test))\n    mse.append(mean_squared_error(y_test, preds_lasso))\n    #rmse = np.sqrt(mse)\n    alphas.append(alpha)\n    print ('R2 Error for alpha = %s is %s'%(alpha, ls.score(X_test, y_test)))\n    plt.pyplot.show()\nR2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e59e0c86b54d1f1a2ff2bd1303385c92994a1569",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.pyplot.plot(mse, alphas)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4cef89daa73d21ea88f47a88d717795ce887fb4c"
      },
      "cell_type": "markdown",
      "source": "### MInimum of MSE can be found at alpha = 0.001"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8911253994774a541c6874eb36321679d759ecea"
      },
      "cell_type": "markdown",
      "source": "#### Ridge Regression CV with alpha = 10"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae3bd75ea64db41dbe5a11ccbc00aa06332f342c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "New_Ridge_lr = Ridge(alpha = 10)\nNew_model = New_Ridge_lr.fit(X,y)\nscores = cross_val_score(New_Ridge_lr, X, y , cv =10, scoring= 'r2')\n#SE_scores = - cross_val_score(New_lr, X, y, cv =10, scoring= 'mean_squared_error')\nprint ('Mean of all the R^2 error after 10 folds of CV is %s.'% scores.mean())\n#rint 'Mean of MSE after 10 folds of CV is %s.' % MSE_scores.mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b50a6b628736596343ddfc323a9e2a44f368c254"
      },
      "cell_type": "markdown",
      "source": "#### Lasso Regression CV with alpha = 0.001"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4a2209a7cde876306b244ac9792b15d5233d9c5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "New_Lasso_lr = Lasso(alpha = 0.001)\nNew_model = New_Lasso_lr.fit(X,y)\nscores = cross_val_score(New_Lasso_lr, X, y , cv =10, scoring= 'r2')\n#SE_scores = - cross_val_score(New_lr, X, y, cv =10, scoring= 'mean_squared_error')\nprint ('Mean of all the R^2 error after 10 folds of CV is %s.'% scores.mean())\n#rint 'Mean of MSE after 10 folds of CV is %s.' % MSE_scores.mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dd39ae9766ed2198b6ddf04ffad11681175e3ddc"
      },
      "cell_type": "markdown",
      "source": "## We've transformed sale prices using log transformation. Make sure to invert the prediction using np.log() transformation to get original scores."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "575d86c6d9b018befd7db34c05f4e6e60fb897f5"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}